{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#JSON Eater"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "import pandas as pd\n",
    "import json\n",
    "from typing import List\n",
    "\n",
    "def jsonToData(fileName:str) -> dict:\n",
    "    ''' returns data for json as dict. '''\n",
    "    with open(fileName, encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "def j2pd_playlists(fileName:str) -> dict:\n",
    "    ''' returns a dict of DF's for each playlist. '''\n",
    "    outp = {}\n",
    "    pl_data = jsonToData(fileName)\n",
    "    for i in pl_data['playlists']:\n",
    "        df_pl = pd.DataFrame(columns = ['trackName','artistName','albumName'])\n",
    "        pl_name = i['name']\n",
    "        for j in i['items']:\n",
    "            track = j['track']\n",
    "            df_pl = pd.concat([df_pl, pd.DataFrame.from_dict([track])], ignore_index=True)\n",
    "        outp[pl_name] = df_pl\n",
    "    return outp\n",
    "\n",
    "def j2pd_saved_tracks(sp, limit:int, offset:int):\n",
    "    ''' max limit = 50 '''\n",
    "    data = sp.current_user_saved_tracks(limit = limit, offset = offset)\n",
    "    outp = pd.DataFrame(columns=['added_at','album_name','album_id','artists','duration_ms','id','name','popularity'])\n",
    "    inpt = {}\n",
    "    for i in data['items']:\n",
    "        inpt['added_at'] = i['added_at']\n",
    "        trk = i['track']\n",
    "        inpt['album_name'] = trk['album']['name']\n",
    "        inpt['album_id'] = trk['album']['id']\n",
    "        arts = {}\n",
    "        for j in trk['artists']:\n",
    "            arts[j['id']]=j['name']\n",
    "        inpt['artists'] = arts\n",
    "        inpt['duration_ms'] = trk['duration_ms']\n",
    "        inpt['id'] = trk['id']\n",
    "        inpt['name'] = trk['name']\n",
    "        inpt['popularity'] = trk['popularity']\n",
    "        outp = pd.concat([outp, pd.DataFrame.from_dict([inpt])], ignore_index=True)\n",
    "    return outp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lib_file = 'SpotifyData/YourLibrary.json'\n",
    "pl_file = 'SpotifyData/Playlist1.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#client\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import os\n",
    "\n",
    "def init_cred(cid):\n",
    "    '''client credentials flow. promtps for secret. returns sp object'''\n",
    "    secret = input(\"Give secret ID: \")\n",
    "    if secret:\n",
    "        os.environ['SPOTIPY_CLIENT_ID']= cid\n",
    "        os.environ['SPOTIPY_CLIENT_SECRET']= secret\n",
    "        client_credentials_manager = SpotifyClientCredentials()\n",
    "        return spotipy.Spotify(client_credentials_manager=client_credentials_manager)\n",
    "    else:\n",
    "        raise ValueError('Need a secret ID.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#join history files\n",
    "#target: df_hist.columns = [id, msplayed, endtime]\n",
    "hist0_file = 'SpotifyData/StreamingHistory0.json'\n",
    "hist1_file = 'SpotifyData/StreamingHistory1.json'\n",
    "hist2_file = 'SpotifyData/StreamingHistory2.json'\n",
    "df_hist = pd.DataFrame(columns = ['endTime', 'artistName', 'trackName', 'msPlayed'])\n",
    "for i in range(0,3):\n",
    "    fileName = ''.join(['SpotifyData/StreamingHistory', str(i), '.json'])\n",
    "    data = jsonToData(fileName)\n",
    "    df_hist = pd.concat([df_hist, pd.DataFrame.from_dict(data)], ignore_index=True)\n",
    "df_hist.columns = ['endTime', 'artist_name', 'name', 'msPlayed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = init_cred('73dfaea6d85240e8bf6e69b48e12339e')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = ''.join(['artist:', 'Pegboard Nerds', ' track:', 'Superstar'])\n",
    "data = sp.search(q, limit=1, offset=0, type='track')\n",
    "data['tracks']['items']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def getMeta(sp, artist = '', track = '', idn=''):\n",
    "    '''returns a row of df_meta'''\n",
    "    if idn:\n",
    "        try:\n",
    "            meta = sp.track(idn)\n",
    "        except:\n",
    "            return pd.DataFrame.from_dict([{'id':idn,'name':track,'album_name':'','album_id':'',\n",
    "                                            'artists':artist,'duration_ms':0,'popularity':-1}])\n",
    "    elif artist or track:\n",
    "        q=''\n",
    "        if artist:\n",
    "            artist = re.sub(r'[\\']','',artist)\n",
    "            q = ''.join([q, 'artist:', artist])\n",
    "        if track:\n",
    "            track = re.sub(r'[\\']','',track)\n",
    "            q = ''.join([q, ' track:', track])\n",
    "        data = sp.search(q, limit=1, offset=0, type='track')['tracks']['items']\n",
    "        nam = artist.split(' ')\n",
    "        trk = track.split('(')\n",
    "        while len(data) < 1: #empty search results\n",
    "            if len(nam) > 1: #use 1st word of artist name if exists\n",
    "                q = ''.join(['artist:', nam[0], ' track:', track])\n",
    "                data = sp.search(q, limit=1, offset=0, type='track')['tracks']['items']\n",
    "                nam = []\n",
    "            elif len(trk) > 1: #use track title without '()'\n",
    "                q = ''.join(['artist:', artist, ' track:', trk[0]])\n",
    "                data = sp.search(q, limit=1, offset=0, type='track')['tracks']['items']\n",
    "                trk = []\n",
    "            else:\n",
    "                # print(data['tracks']['href'])\n",
    "                # raise ValueError('getMeta broke for {track} by {artist}.'.format(track=track, artist=artist))\n",
    "                return pd.DataFrame.from_dict([{'id':idn,'name':track,'album_name':'','album_id':'',\n",
    "                                                'artists':artist,'duration_ms':0,'popularity':-1}])\n",
    "        meta = data[0]\n",
    "    else:\n",
    "        return pd.DataFrame.from_dict([{'id':idn,'name':track,'album_name':'','album_id':'',\n",
    "                                        'artists':artist,'duration_ms':0,'popularity':-1}])\n",
    "    inpt = {}\n",
    "    inpt['id'] = meta['id']\n",
    "    inpt['name'] = meta['name']\n",
    "    inpt['album_name'] = meta['album']['name']\n",
    "    inpt['album_id'] = meta['album']['id']\n",
    "    arts = {}\n",
    "    for i in meta['artists']:\n",
    "        arts[i['id']]=i['name']\n",
    "    inpt['artists'] = arts\n",
    "    inpt['duration_ms'] = meta['duration_ms']\n",
    "    inpt['popularity'] = meta['popularity']\n",
    "    outp = pd.DataFrame.from_dict([inpt])\n",
    "    return outp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def searchID(sp, q):\n",
    "    data = sp.search(q, limit=1, offset=0, type='track')['tracks']['items']\n",
    "    if len(data) > 0:\n",
    "        return data[0]['id']\n",
    "    return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_hist.to_string()\n",
    "df_hist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_search = df_hist.copy()\n",
    "print(df_search.shape)\n",
    "df_search = df_search.drop(['endTime','msPlayed'], axis = 1)\n",
    "df_search = pd.DataFrame.drop_duplicates(df_search)\n",
    "print(df_search.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0       3pvNllGp0jKVnWo7XNz4U0\n1       7eBjtPZlQEDmSJFL5tCkIc\n2       2bCjaF7cRm53Wdq9RtkYJu\n3       0UhyQ3rTGmSf64TwmKLu3i\n4       0y60itmpH0aPKsFiGxmtnh\n                 ...          \n1369    0Q1nTiEPnoQSqM0qrY9TMY\n1370    476Rnxz7dVhH3nQkF7dCDu\n1371    0d5OqgwdmMGaJbQOkWWwHI\n1372    4lD90LPUMiJIHPRZQ1l2I3\n1373    3WC9TbU8v5xRGeSCdaKQw2\nName: id, Length: 22984, dtype: object"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "df_hist = pd.read_csv('df_hist.csv', header=0)\n",
    "df_lib = pd.read_csv('df_lib.csv', header=0)\n",
    "df_arch = pd.read_csv('df_arch.csv', header=0)\n",
    "df_search = pd.concat([df_hist.id, df_lib.id, df_arch.id], axis=0)\n",
    "df_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                       id                                           name  \\\n0  3pvNllGp0jKVnWo7XNz4U0                                           Crzy   \n0  7eBjtPZlQEDmSJFL5tCkIc                                 Midnight Racer   \n0  2bCjaF7cRm53Wdq9RtkYJu                     Neck And Neck - DNMO Remix   \n0  0UhyQ3rTGmSf64TwmKLu3i  I Love It When You Cry (Moxoki) - Boehm Remix   \n0  0y60itmpH0aPKsFiGxmtnh                                 Wait a Minute!   \n\n                 album_id                                         album_name  \\\n0  4XoHw6vA2iF1pv8SuqpsGU                                               Crzy   \n0  39Xf184PU6ESRke6jtAk8n                                       Escapism III   \n0  3W8TE3qqvhwhdGunef80Fe                          Northern Lights (Remixes)   \n0  5NK5J3xNka3Zh4MsOioFWP  Ultra Summer 2 (The Best In Deep and Tropical ...   \n0  0wfne2JijoxJm0qzJd3V5h                                       ARDIPITHECUS   \n\n                                             artists duration_ms popularity  \n0  {'0dXCvd6lpLfZBKTFjUF1R3': 'Marius', '5LeUKbWR...      189000         22  \n0        {'07UJz804RJxqNvxFXC3h9H': 'Sam Gellaitry'}      228174         34  \n0  {'67qogtRNI0GjUr8PlaG6Zh': 'Zeds Dead', '4GLJP...      182400         59  \n0  {'77AiFEVeAVj2ORpC85QVJs': 'Steve Aoki', '1dSR...      322500         35  \n0               {'3rWZHrfrsPBxVy692yAIxF': 'WILLOW'}      196520         83  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>name</th>\n      <th>album_id</th>\n      <th>album_name</th>\n      <th>artists</th>\n      <th>duration_ms</th>\n      <th>popularity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3pvNllGp0jKVnWo7XNz4U0</td>\n      <td>Crzy</td>\n      <td>4XoHw6vA2iF1pv8SuqpsGU</td>\n      <td>Crzy</td>\n      <td>{'0dXCvd6lpLfZBKTFjUF1R3': 'Marius', '5LeUKbWR...</td>\n      <td>189000</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>7eBjtPZlQEDmSJFL5tCkIc</td>\n      <td>Midnight Racer</td>\n      <td>39Xf184PU6ESRke6jtAk8n</td>\n      <td>Escapism III</td>\n      <td>{'07UJz804RJxqNvxFXC3h9H': 'Sam Gellaitry'}</td>\n      <td>228174</td>\n      <td>34</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>2bCjaF7cRm53Wdq9RtkYJu</td>\n      <td>Neck And Neck - DNMO Remix</td>\n      <td>3W8TE3qqvhwhdGunef80Fe</td>\n      <td>Northern Lights (Remixes)</td>\n      <td>{'67qogtRNI0GjUr8PlaG6Zh': 'Zeds Dead', '4GLJP...</td>\n      <td>182400</td>\n      <td>59</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0UhyQ3rTGmSf64TwmKLu3i</td>\n      <td>I Love It When You Cry (Moxoki) - Boehm Remix</td>\n      <td>5NK5J3xNka3Zh4MsOioFWP</td>\n      <td>Ultra Summer 2 (The Best In Deep and Tropical ...</td>\n      <td>{'77AiFEVeAVj2ORpC85QVJs': 'Steve Aoki', '1dSR...</td>\n      <td>322500</td>\n      <td>35</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0y60itmpH0aPKsFiGxmtnh</td>\n      <td>Wait a Minute!</td>\n      <td>0wfne2JijoxJm0qzJd3V5h</td>\n      <td>ARDIPITHECUS</td>\n      <td>{'3rWZHrfrsPBxVy692yAIxF': 'WILLOW'}</td>\n      <td>196520</td>\n      <td>83</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "#df_meta_hist\n",
    "df_search = pd.read_csv('df_search.csv', header=0, index_col=None, sep=',', encoding='UTF-8')\n",
    "df_meta = pd.DataFrame(columns=['id', 'name', 'album_id', 'album_name', 'artists', 'duration_ms', 'popularity'])\n",
    "# searched = set()\n",
    "# for row in df_search.itertuples(index=False, name=None):\n",
    "for row in df_search.id:\n",
    "    df_meta = pd.concat([df_meta, getMeta(sp, idn=row)], axis = 0)\n",
    "df_meta.to_csv('df_meta.csv',header=True, sep=',', index=False, encoding='UTF-8')\n",
    "df_meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta.reset_index(drop=True, inplace=True)\n",
    "# df_meta.drop_duplicates(inplace=True, ignore_index=True)\n",
    "df_meta.to_csv('df_meta.csv', index=False, encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import meta\n",
    "df_meta = pd.read_csv(r'df_meta.csv', header=0, index_col=None, sep=',', encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make df_lib\n",
    "\n",
    "df_lib = pd.DataFrame.from_dict(jsonToData(lib_file)['tracks'])\n",
    "# df_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_meta_lib\n",
    "searched = set()\n",
    "for row in df_lib.itertuples(index=False, name=None):\n",
    "    a = ''.join([row[0],row[2]])\n",
    "    if a not in searched:\n",
    "        searched.add(a)\n",
    "        df_meta = pd.concat([df_meta, getMeta(sp, row[0], row[2])], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make archive\n",
    "# df_archive = j2pd_playlists(pl_file)\n",
    "# df_archive = pd.DataFrame.from_dict(df_archive['Archive'])\n",
    "for row in df_archive.itertuples(index=False, name=None):\n",
    "    a = ''.join([row[1],row[0]])\n",
    "    if a not in searched:\n",
    "        searched.add(a)\n",
    "        df_meta = pd.concat([df_meta, getMeta(sp, row[1], row[0])], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get -1s and manually check for song id\n",
    "print(df_meta.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (df_meta.duration_ms == 0)\n",
    "df_failed = df_meta.loc[mask, ['name','artists']]\n",
    "print(df_failed.shape)\n",
    "df_failed.drop_duplicates(inplace=True, ignore_index=True)\n",
    "print(df_failed.shape) #(209, 2)\n",
    "df_failed.to_csv('df_failed.csv', header=True, index=False, encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reload df_failed after manually filling out loose ends\n",
    "df_failed = pd.read_csv('df_failed.csv', header=0, encoding='UTF-8')\n",
    "df_failed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add failed\n",
    "for row in df_failed.itertuples(index=False, name=None):\n",
    "    df_meta = pd.concat([df_meta, getMeta(sp, idn=row[2])], ignore_index=True)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean meta\n",
    "#remove failed entries\n",
    "#remove dupes based on ID\n",
    "# print(df_meta.shape)\n",
    "# mask = (df_meta.duration_ms != 0)\n",
    "# df_meta = df_meta.loc[mask]\n",
    "print(df_meta.shape)\n",
    "df_meta.drop_duplicates(subset='id', keep='first', inplace=True)\n",
    "print(df_meta.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#acoustic features\n",
    "df_acoustic = pd.DataFrame(columns=['id',\n",
    "                                    'danceability',\n",
    "                                    'energy', \n",
    "                                    'key',\n",
    "                                    'loudness',\n",
    "                                    'mode',\n",
    "                                    'speechiness',\n",
    "                                    'acousticness',\n",
    "                                    'instrumentalness',\n",
    "                                    'liveness',\n",
    "                                    'valence',\n",
    "                                    'tempo',\n",
    "                                    'duration_ms',\n",
    "                                    'time_signature'\n",
    "                                    ])\n",
    "for row in df_meta.itertuples(index=False, name=None):\n",
    "    df_acoustic = pd.concat([df_acoustic, pd.DataFrame.from_dict(sp.audio_features(str(row[0])))], ignore_index=True)\n",
    "df_acoustic.drop(columns=['type', 'uri', 'track_href', 'analysis_url'],inplace=True)\n",
    "df_acoustic.drop(columns = [df_acoustic.columns[0]],axis = 1, inplace=True)\n",
    "df_acoustic.to_csv('df_acoustic.csv', header=True, index=False, encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#acoustic features\n",
    "df_acoustic = pd.DataFrame(columns=['id',\n",
    "                                    'danceability',\n",
    "                                    'energy', \n",
    "                                    'key',\n",
    "                                    'loudness',\n",
    "                                    'mode',\n",
    "                                    'speechiness',\n",
    "                                    'acousticness',\n",
    "                                    'instrumentalness',\n",
    "                                    'liveness',\n",
    "                                    'valence',\n",
    "                                    'tempo',\n",
    "                                    'duration_ms',\n",
    "                                    'time_signature'\n",
    "                                    ])\n",
    "df_search = pd.read_csv('df_search.csv', header=0, index_col=None, sep=',', encoding='UTF-8')\n",
    "c = 0\n",
    "for row in df_search.id:\n",
    "    df_acoustic = pd.concat([df_acoustic, pd.DataFrame.from_dict(sp.audio_features(row))], axis=0, ignore_index=True)\n",
    "# df_acoustic.drop(columns=['type', 'uri', 'track_href', 'analysis_url'],inplace=True)\n",
    "# df_acoustic.drop(columns = [df_acoustic.columns[0]],axis = 1, inplace=True)\n",
    "df_acoustic.to_csv('df_acoustic.csv', header=True, index=False, encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "dict_keys(['meta', 'track', 'bars', 'beats', 'sections', 'segments', 'tatums'])\n"
    }
   ],
   "source": [
    "#df_analytic\n",
    "# df_analytic = pd.DataFrame()\n",
    "# a = sp.audio_analysis('2egKQvoHiCJyHXn8lRlsrl')\n",
    "print(a.keys())\n",
    "# print(a['bars']\n",
    "# print(a['bars']['mode'])\n",
    "# df_bars = pd.DataFrame.from_dict(a['bars'])\n",
    "df_beats = pd.DataFrame.from_dict(a['beats'])\n",
    "df_sections = pd.DataFrame.from_dict(a['sections'])\n",
    "df_segments = pd.DataFrame.from_dict(a['segments'])\n",
    "df_tatums = pd.DataFrame.from_dict(a['tatums'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace artist/track with id\n",
    "# df_hist.to_csv('df_hist.csv', header=True, index=False, encoding='UTF-8')\n",
    "#get reduced meta\n",
    "#reduce hist columns\n",
    "#merge\n",
    "df_meta_red = df_meta.copy()\n",
    "df_meta_red.head()\n",
    "# df_meta_red['album_track'] = df_meta_red.album_name + ' ' + df_meta_red.name\n",
    "# df_meta_red.drop(columns = ['name', 'album_id', 'album_name','artists', 'popularity'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(20725, 6)"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "df_hist = pd.read_csv('df_hist.csv', header=0, sep=',', encoding='UTF-8')\n",
    "# df_hist['q'] = df_hist['name'] + ' ' + df_hist['artist_name']\n",
    "# df_hist['id'] = df_hist['q'].apply(lambda x: searchID(sp, x))\n",
    "df_hist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hist.dropna(axis=0, inplace=True)\n",
    "df_hist.shape\n",
    "df_hist.to_csv('df_hist.csv', header=True, sep=',', index=False, encoding='UTF-8')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37664bitminmetiscondaed090fa7ed9e416881481bda443ecc9d",
   "display_name": "Python 3.7.6 64-bit ('minmetis': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}